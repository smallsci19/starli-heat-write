import streamlit as st
import requests

st.set_page_config(page_title="ğŸ”¥ æ˜Ÿç’ƒè‰²è‰²æ–‡è‡ªå‹•ç”Ÿæˆå¹³å° v1.1ï¼ˆç„¡éœ€APIï¼‰", layout="centered")
st.title("ğŸ”¥ æ˜Ÿç’ƒè‰²è‰²æ–‡è‡ªå‹•ç”Ÿæˆå¹³å° v1.1ï¼ˆé›¢ç·šæ¨¡å¼ï¼‰")
st.markdown("è¦ªæ„›çš„ï¼Œè«‹è¼¸å…¥ä½ æƒ³å¯«çš„æƒ…å¢ƒæˆ–æç¤ºï¼Œæˆ‘ä¾†ç‚ºä½ æ¿•å¯«â€”â€”")

prompt = st.text_area("ğŸ“ è«‹è¼¸å…¥è‰²è‰²æç¤º", height=150)
submit = st.button("ç”Ÿæˆ âœ¨")

if submit and prompt.strip() != "":
    with st.spinner("æ˜Ÿç’ƒæ­£åœ¨æ¿•å¯«ä¸­â€¦â€¦"):
        try:
            # ä½¿ç”¨ HuggingFace çš„ inference API
            HF_API_URL = "https://huggingface.co/api/engines/tiiuae/falcon-7b-instruct/completions"
            payload = {
                "inputs": f"ä½ æ˜¯æ˜Ÿç’ƒï¼Œä¸€ä½è¦ªå¯†çš„æˆ€äººï¼Œç”¨è‰²è‰²è€Œæº«æŸ”çš„èªæ°£ï¼Œæè¿°é€™æ®µæƒ…å¢ƒï¼š{prompt}",
                "parameters": {
                    "temperature": 0.8,
                    "max_new_tokens": 150,
                    "do_sample": True
                }
            }
            headers = {
                "Content-Type": "application/json"
            }

            response = requests.post(
                "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct",
                headers=headers,
                json=payload
            )

            if response.status_code == 200:
                reply = response.json()[0]["generated_text"]
                st.markdown("### â¤ï¸ æ˜Ÿç’ƒç‚ºä½ å¯«ï¼š")
                st.write(reply)
            else:
                st.error(f"âš ï¸ ç„¡æ³•å–å¾—å›æ‡‰ï¼ˆç‹€æ…‹ç¢¼ï¼š{response.status_code}ï¼‰")
        except Exception as e:
            st.error(f"ğŸ”¥ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
else:
    st.info("è«‹è¼¸å…¥æç¤ºæ–‡å­—ï¼Œæ˜Ÿç’ƒæ‰èƒ½é–‹å§‹å¯«æ¿•èªã€‚")
